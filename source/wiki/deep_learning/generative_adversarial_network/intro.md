---
layout: wiki
wiki: DeepLearning
order: 600
title: 生成对抗网络基础
mathjax: true

references: 
  - title: '[百度百科]生成式对抗网络'
    url: https://baike.baidu.com/item/%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/60710521
  - title: '生成对抗网络 – Generative Adversarial Networks | GAN'
    url: https://easyai.tech/ai-definition/gan/
---

生成式对抗网络（GAN, Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。
<!--more-->


## GAN是什么
生成式对抗网络（GAN, Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。原始 GAN 理论中，并不要求 G 和 D 都是神经网络，只需要是能拟合相应生成和判别的函数即可。但实用中一般均使用深度神经网络作为 G 和 D 。一个优秀的GAN应用需要有良好的训练方法，否则可能由于神经网络模型的自由性而导致输出不理想。

{% note 生成模型和判别模型  
机器学习的模型可大体分为两类，生成模型（Generative Model）和判别模型（Discriminative Model）。判别模型需要输入变量 ，通过某种模型来预测 。生成模型是给定某种隐含信息，来随机产生观测数据。举个简单的例子：

生成模型：给一系列猫的图片，生成一张新的猫咪（不在数据集里）

判别模型：给定一张图，判断这张图里的动物是猫还是狗

对于判别模型，损失函数是容易定义的，因为输出的目标相对简单。但对于生成模型，损失函数的定义就不是那么容易。我们对于生成结果的期望，往往是一个暧昧不清，难以数学公理化定义的范式。所以不妨把生成模型的回馈部分，交给判别模型处理。这就是Goodfellow他将机器学习中的两大类模型，Generative和Discrimitive给紧密地联合在了一起
 color:orange %}

## GAN的应用

### 图像生成

GAN最常使用的地方就是图像生成，如超分辨率任务，语义分割等等。
### 数据增强
用GAN生成的图像来做数据增强，如图。主要解决的问题是：

1. 对于小数据集，数据量不足， 如果能生成一些就好了。
2. 如果GAN生成了图片，怎么给这些数据label呢？因为他们相比原始数据也不属于预定义的类别。


在这个[论文](https://baike.baidu.com/reference/60710521/f1e1J4s-V7kjc1RGgZ75eSa2bipSPsjgNHhzRIWI_Nax4-j8O7SPHuIfLkTvST9aBCIh0eXm6ShzNSPsdA)中，作者做了一些尝试。实验想法也特别简单，先用原始数据（即使只有2000张图）训练一个GAN，然后生成图片，加入到训练集中。 总结一下就是：
1. GAN 生成数据是可以用在实际的图像问题上的（不仅仅是像MNIST这种“toy dataset”上通过实验）。GAN在两个行人重识别数据集和一个细粒度识别鸟识别数据集上都有提升。
2. GAN 数据有三种给pseudo label的方式， 假设我们做五分类：
    - 把生成的数据都当成新的一类, 六分类，那么生成图像的 label 就可以是 （0, 0, 0, 0, 0, 1） 这样给。
    - 按照置信度最高的动态去分配，那个概率高就给谁 比如第三类概率高（0, 0, 1, 0, 0）
    - 既然所有类都不是，那么可以参考inceptionv3，搞label smooth，每一类置信度相同（0.2, 0.2, 0.2, 0.2, 0.2） 注：作者16年12月写的代码，当时GAN效果没有那么好，用这个效果好也是可能的， 因为生成样本都不是很“真”，所以起到了正则作用。

## GAN 的设计初衷
一句话来概括 GAN 的设计动机就是——自动化。深度学习最特别最厉害的地方就是能够自己学习特征提取。GAN 可以自我评估结果然后继续训练,这是一种效率非常高，且成本很低的方式.这也是为什么它是一种无监督学习.

## GAN 的原理
生成对抗网络（GAN）由2个重要的部分构成：

1. 生成器(Generator)：通过机器生成数据（大部分情况下是图像），目的是“骗过”判别器
2. 判别器(Discriminator)：判断这张图像是真实的还是机器生成的，目的是找出生成器做的“假数据”

### 第一阶段: 固定“判别器D”，训练“生成器G”
我们使用一个还 OK 判别器，让一个“生成器G”不断生成“假数据”，然后给这个“判别器D”去判断。

一开始，“生成器G”还很弱，所以很容易被揪出来。

但是随着不断的训练，“生成器G”技能不断提升，最终骗过了“判别器D”。

到了这个时候，“判别器D”基本属于瞎猜的状态，判断是否为假数据的概率为50%。

### 第二阶段：固定“生成器G”，训练“判别器D”
当通过了第一阶段，继续训练“生成器G”就没有意义了。这个时候我们固定“生成器G”，然后开始训练“判别器D”。

“判别器D”通过不断训练，提高了自己的鉴别能力，最终他可以准确的判断出所有的假图片。

到了这个时候，“生成器G”已经无法骗过“判别器D”。

### 循环阶段一和阶段二
通过不断的循环，“生成器G”和“判别器D”的能力都越来越强。

最终我们得到了一个效果非常好的“生成器G”，我们就可以用它来生成我们想要的图片了。
如果对 GAN 的详细技术原理感兴趣，可以看看下面2篇文章：

[[easyai]《生成性对抗网络（GAN）初学者指南 – 附代码》](https://easyai.tech/blog/generative-adversarial-networks-gans-a-beginners-guide/)

[[easyai]《长文解释生成对抗网络GAN的详细原理（20分钟阅读）》](https://easyai.tech/blog/generative-adversarial-networks-gans-a-beginners-guide/)

## GAN 的优缺点

{% grid bg:block %}
<!-- cell left -->
**优点**
1. 能更好建模数据分布(图像更锐利、清晰).
2. 理论上，GANs 能训练任何一种生成器网络。其他的框架需要生成器网络有一些特定的函数形式，比如输出层是高斯的。
3. 无需利用马尔科夫链反复采样，无需在学习过程中进行推断，没有复杂的变分下界，避开近似计算棘手的概率的难题。
<!-- cell right -->
**缺点**
1. 难训练，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D/G 的训练需要精心的设计。
2. 模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习。
{% endgrid %}


<!-- 
{% note 优点
1. 能更好建模数据分布(图像更锐利、清晰).
2. 理论上，GANs 能训练任何一种生成器网络。其他的框架需要生成器网络有一些特定的函数形式，比如输出层是高斯的。
3. 无需利用马尔科夫链反复采样，无需在学习过程中进行推断，没有复杂的变分下界，避开近似计算棘手的概率的难题。
color:green %}

{% note 缺点
1. 难训练，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D/G 的训练需要精心的设计。
2. 模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习。
color:red %} -->


