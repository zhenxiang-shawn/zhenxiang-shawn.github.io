<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 5.4.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>检测模糊图片的几种方法 - J. Tech.</title>

  
    <meta name="description" content="为什么要做模糊检测 ?在机器学习准备数据的时候,有些数据并不尽如人意. 比如在计算机视觉训练时,图片数据集中有一些收集的图片清晰度不够,这会影响到后续的训练和模型的准确度. 准备图片数据的时候一般会根据图片质量选择是否先给图片降噪,然后把较为模糊的图片给去掉. 除此以外还可以用来做自动图像分级, 在视频流做OCR的时候可以过滤掉一些质量不好的图片来节省算力. 本文主要为讨论了模糊图片的检测的两种方">
<meta property="og:type" content="article">
<meta property="og:title" content="检测模糊图片的几种方法">
<meta property="og:url" content="https://zhenxiang-shawn.github.io/2022/03/22/2022-03-22-blur-detection/index.html">
<meta property="og:site_name" content="J. Tech.">
<meta property="og:description" content="为什么要做模糊检测 ?在机器学习准备数据的时候,有些数据并不尽如人意. 比如在计算机视觉训练时,图片数据集中有一些收集的图片清晰度不够,这会影响到后续的训练和模型的准确度. 准备图片数据的时候一般会根据图片质量选择是否先给图片降噪,然后把较为模糊的图片给去掉. 除此以外还可以用来做自动图像分级, 在视频流做OCR的时候可以过滤掉一些质量不好的图片来节省算力. 本文主要为讨论了模糊图片的检测的两种方">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-03-21T16:00:00.000Z">
<meta property="article:modified_time" content="2022-03-21T16:00:00.000Z">
<meta property="article:author" content="Zhenxiang Jin">
<meta property="article:tag" content="Computer Vision">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Data Clean">
<meta name="twitter:card" content="summary">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  
</head>

<body>
  


  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://github.com/zhenxiang-shawn/zhenxiang-shawn.github.io/blob/main/source/_imgs/jin_logo.png?raw=true" onerror="javascript:this.classList.add('error');this.src='https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">J. Tech.</div><div class="sub normal cap">求知若饥</div><div class="sub hover cap" style="opacity:0">虚心若愚</div></a></div>
<nav class="menu dis-select"><a class="nav-item active" href="/">博客</a><a class="nav-item" href="/wiki/">项目</a><a class="nav-item" href="/notes/">便笺</a><a class="nav-item" href="/about/">关于</a><a class="nav-item" href="/more/">更多</a><a class="nav-item" href="/friends/">友链</a></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%81%9A%E6%A8%A1%E7%B3%8A%E6%A3%80%E6%B5%8B"><span class="toc-text">为什么要做模糊检测 ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%951-%E4%BD%BF%E7%94%A8OpenCV%E5%92%8C%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90%E8%AE%A1%E7%AE%97"><span class="toc-text">方法1: 使用OpenCV和拉普拉斯算子计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%952-%E4%BD%BF%E7%94%A8OpenCV-%E5%92%8C-Fast-Fourier-Transform-FFT-%E6%A3%80%E6%B5%8B%E6%A8%A1%E7%B3%8A%E5%9B%BE%E7%89%87"><span class="toc-text">方法2: 使用OpenCV 和 Fast Fourier Transform (FFT)检测模糊图片</span></a></li></ol></div></div></div>


</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/zhenxiang-shawn" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.3/social/08a41b181ce68.svg"/></a><a class="social" href="mailto:zhenxiang-shawn@outlook.com" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://img.cubik65536.top/mail-bulk-solid.svg"/></a><a class="social" href="/about/#comments" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.3/social/942ebbf1a4b91.svg"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%8A%A0%E6%B2%B9%E7%AB%99/">技术加油站</a></div><div id="post-meta">发布于&nbsp;<time datetime="2022-03-21T16:00:00.000Z">2022-03-22</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>检测模糊图片的几种方法</span></h1>
<h2 id="为什么要做模糊检测"><a href="#为什么要做模糊检测" class="headerlink" title="为什么要做模糊检测 ?"></a>为什么要做模糊检测 ?</h2><p>在机器学习准备数据的时候,有些数据并不尽如人意. 比如在计算机视觉训练时,图片数据集中有一些收集的图片清晰度不够,这会影响到后续的训练和模型的准确度. 准备图片数据的时候一般会根据图片质量选择是否先给图片降噪,然后把较为模糊的图片给去掉. 除此以外还可以用来做自动图像分级, 在视频流做OCR的时候可以过滤掉一些质量不好的图片来节省算力. 本文主要为讨论了模糊图片的检测的两种方法.</p>
<span id="more"></span>

<h2 id="方法1-使用OpenCV和拉普拉斯算子计算"><a href="#方法1-使用OpenCV和拉普拉斯算子计算" class="headerlink" title="方法1: 使用OpenCV和拉普拉斯算子计算"></a>方法1: 使用OpenCV和拉普拉斯算子计算</h2><p>一般来说，如果要检测图片的模糊程度，首先要考虑的方法是计算图像的快速傅里叶变换，然后检查低频和高频的分布：如果图像只有有少量的高频，那么图像就会被认为是模糊的．然而，定义什么算低数量的高频或者什么是高数量的高频是相当困难的。</p>
<p>根据<a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/Analysis-of-focus-measure-operators-for-Pertuz-Puig/8c675bf5b542b98bf81dcf70bd869ab52ab8aae9?p2df">Pertuz 的研究</a>, 仅使用基本的灰度像素强度统计, 评估图像的局部二值模式就可以计算一个单一的浮点值来表示一个给定图像的模糊程度. 一般的,我们使用<strong>Tenengrad梯度方法</strong>或者<strong>Laplacian梯度方法</strong>. 这两个不同算法在模糊检测时的结果几近相同,而使用Laplacian算子会减少运算量(Tenengrad梯度方法会计算x,y两个方向的梯度, 而Laplacian梯度方法只用计算Laplacian算子矩阵和灰度图的卷积), 所以我们选择Laplacian算子来检测图片的模糊程度.</p>
<p>下边是使用opencv检测图片的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detect_pic_blur</span>(<span class="params">img_path</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="comment"># read picture</span></span><br><span class="line">    img = cv2.imread(img_path)</span><br><span class="line">    <span class="comment"># remove color</span></span><br><span class="line">    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) </span><br><span class="line">    <span class="comment"># calculate the Laplacian value of the img</span></span><br><span class="line">    fm = cv.Laplacian(gray, cv2.CV_64F).var() </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;图片的拉普拉斯值为:<span class="subst">&#123;fm&#125;</span>&#x27;</span>)</span><br><span class="line">    threshold = <span class="number">120</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span> <span class="keyword">if</span> fm &lt;= threshold <span class="keyword">else</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>

<p>使用此方法的话,一般需要对不同的数据集采用不同的threshold.</p>
<h2 id="方法2-使用OpenCV-和-Fast-Fourier-Transform-FFT-检测模糊图片"><a href="#方法2-使用OpenCV-和-Fast-Fourier-Transform-FFT-检测模糊图片" class="headerlink" title="方法2: 使用OpenCV 和 Fast Fourier Transform (FFT)检测模糊图片"></a>方法2: 使用OpenCV 和 Fast Fourier Transform (FFT)检测模糊图片</h2><p>当数据集多的时候,拉普拉斯方法需要大量的手动调整来定义图像是否模糊的“阈值”。如果您可以控制您的照明条件、环境和图像捕获过程，那么它的效果会非常好. 但是如果实验数据收集的时候变量太大(不同拍照设备,不同天气)的话,这样拉普拉斯算子算法就不是一个很好的选择.<br>这个方法的思路是使用快速傅里叶变换来计算图片的模糊值. 在计算机视觉方面，我们经常将 FFT 视为一种图像处理工具，可以在两个域中表示图像：</p>
<ul>
<li>傅里叶域</li>
<li>空间域</li>
</ul>
<p>因此，FFT 用实部和虚部表示图像。通过分析这些值，我们可以执行图像处理例程，例如模糊、边缘检测、阈值处理、纹理分析，甚至是模糊检测。更多关于傅里叶变换的内容请参考<a target="_blank" rel="noopener" href="https://homepages-inf-ed-ac-uk.translate.goog/rbf/HIPR2/fourier.htm?_x_tr_sl=auto&_x_tr_tl=zh-CN&_x_tr_hl=zh-CN&_x_tr_pto=op">FFT and it’s relation to image processing</a></p>
<p>下边是使用opencv检测图片的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detect_img_blur_fft</span>(<span class="params">img_path, size=<span class="number">60</span>, threshold=<span class="number">10</span>, vis=<span class="literal">False</span></span>):</span><br><span class="line">    img = cv2.imread(img_path)</span><br><span class="line">    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    (height, width) = img_gray.shape</span><br><span class="line">    <span class="comment"># compute center coordinates</span></span><br><span class="line">    (cX, cY) = (<span class="built_in">int</span>(width / <span class="number">2.0</span>), <span class="built_in">int</span>(height / <span class="number">2.0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute FFT </span></span><br><span class="line">    fft = np.fft.fft2(img_gray)</span><br><span class="line">    fft_shift = np.fft.fftshift(fft)</span><br><span class="line">    <span class="comment"># Zero-out the center of our FFT shift (i.e., to remove low frequencies) </span></span><br><span class="line">    fft_shift[cY - size:cY + size, cX - size:cX + size] = <span class="number">0</span></span><br><span class="line">    <span class="comment"># Apply the inverse shift to put the DC component back in the top-left</span></span><br><span class="line">    fftShift = np.fft.ifftshift(fft_shift)</span><br><span class="line">    <span class="comment"># apply inverse FFT</span></span><br><span class="line">    recon = np.fft.ifft2(fftShift)</span><br><span class="line">    magnitude = <span class="number">20</span> * np.log(np.<span class="built_in">abs</span>(recon))</span><br><span class="line">    mean = np.mean(magnitude)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Mean: <span class="subst">&#123;mean&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># the image will be considered &quot;blurry&quot; if the mean value of the</span></span><br><span class="line">    <span class="comment"># magnitudes is less than the threshold value</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span> <span class="keyword">if</span> mean &lt;=threshold <span class="keyword">else</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>


<div class="article-footer reveal fs14"><section id="references"><div class="header"><span>参考资料</span></div><div class="body"><ul><li class="post-title"><a href="https://pyimagesearch.com/2020/06/15/opencv-fast-fourier-transform-fft-for-blur-detection-in-images-and-video-streams/" target="_blank" rel="external nofollow noopener noreferrer">OpenCV fast fourier transform FFT for blur detection in images and video streams</a></li><li class="post-title"><a href="https://pyimagesearch-com.translate.goog/2015/09/07/blur-detection-with-opencv/?_x_tr_sl=auto&_x_tr_tl=zh-CN&_x_tr_hl=zh-CN" target="_blank" rel="external nofollow noopener noreferrer">Blur detection with OpenCV</a></li></ul></div></section><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/2022/03/14/hello-world/">Hello World<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/2022/03/23/2022-03-23-optimize-img-load/">如何在Server上优化博客上图片的加载速度<span class="note">较新</span></a></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="zhenxiang-shawn/beaudar_comments" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs14">博客</span><a href="/">近期</a><a href="/blog/categories/">分类</a><a href="/blog/tags/">标签</a><a href="/blog/archives/">归档</a></div><div class="sitemap-group"><span class="fs14">项目</span><a href="/wiki/tags/LeetCode/">LeetCode</a><a href="/wiki/tags/DeepLearning/">DeepLearning</a><a href="/wiki/tags/Python/">Python</a></div><div class="sitemap-group"><span class="fs14">社交</span><a href="/friends/">友链</a><a href="/more/#comments">留言板</a></div><div class="sitemap-group"><span class="fs14">更多</span><a href="/about/">关于本站</a><a target="_blank" rel="noopener" href="https://github.com/zhenxiang-shawn">GitHub</a></div></div><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="https://zhenxiang-shawn.github.io/">@Zhenxiang Jin</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.6.1" title="v1.6.1">Stellar</a> 作为主题，您可以在 <a target="_blank" rel="noopener" href="https://github.com/zhenxiang-shawn/zhenxiang-shawn.github.io/">GitHub</a> 找到本站源码。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.6.1';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://cdn.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
